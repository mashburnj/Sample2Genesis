{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm 5 Data Combiner / Dimension Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler #Can also try MinMaxScaler or MaxAbsScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open directory with the spectrograms and audio data.\n",
    "used_raw_data = True\n",
    "\n",
    "os.chdir('..')\n",
    "os.chdir('./data/')\n",
    "\n",
    "SampleFeatures = pd.read_csv('SampleSpectra5.csv', index_col = 0)\n",
    "\n",
    "if used_raw_data:\n",
    "    SampleWav = pd.read_csv('SampleWav5.csv', index_col = 0)\n",
    "    SampleFeatures = pd.concat([SampleFeatures, SampleWav], axis = 1, join = 'inner')\n",
    "    del SampleWav\n",
    "\n",
    "print(len(SampleFeatures),'patches created with algorithm 5 loaded.')\n",
    "\n",
    "# Have to rescale before using PCA\n",
    "scaler = StandardScaler()\n",
    "SampleFeatures = scaler.fit_transform(SampleFeatures)\n",
    "# To do: extract vectors of means and stdevs to transform input for prediction later.\n",
    "# Recall Z-score formula: (x-m)/s. That's exactly what this has done.\n",
    "np.savetxt('mean5.csv',scaler.mean_, delimiter = ',')\n",
    "np.savetxt('scale5.csv',scaler.scale_, delimiter = ',') #stdev\n",
    "\n",
    "pca = PCA(n_components = 200) # Has to be <= min(# samples, # features)\n",
    "pca.fit(SampleFeatures)\n",
    "ReducedFeatures = pca.transform(SampleFeatures)\n",
    "print(pca.explained_variance_)\n",
    "print('reduced shape ', ReducedFeatures.shape)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVING THIS PCA TO DISK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "os.chdir('./models/')\n",
    "\n",
    "with open('pca5.pkl','wb') as export_file:\n",
    "    pk.dump(pca, export_file)\n",
    "\n",
    "# In training script and predictor program, use the following\n",
    "# pca_reload = pk.load(open(\"pca.pkl\",'rb'))\n",
    "# result_new = pca_reload.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
